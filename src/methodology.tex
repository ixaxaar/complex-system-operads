% Methodology section
Modeling temporality is central to be able to capture the true essence of complex systems. Components of complex systems interact with one another and evolve across multiple time scales, leading to emergent phenomena that cannot be understood through static or purely structural models. However for modeling such systems, it is sufficient to model the participant components and their interactions as stochastic processes that evolve over time, rather than modeling time explicitly. This implies our model must capture sequences that represent the evolution of states and interactions over time, while preserving causal relationships. The different scales of time are captured by the hierarchical structure of operads, where different levels of the hierarchy can represent dynamics occurring at different time scales, with higher levels operating at slower time scales than lower ones.

We develop a novel mathematical framework, based on WD-operads, to model complex systems through temporal-causal relationships. Our approach enriches the established theory of WD-operads with temporal probability structures, creating operads that naturally capture sequential dynamics and causal interactions.

\subsection{Temporal Probability Spaces}

Let us first define the notion of temporal probability spaces, which will serve as an enriching category for our operads. We denote the category of temporal probability spaces as $\mathbf{TempProb}$.

Each object of $\mathbf{TempProb}$ is a temporal probability space, $\Omega_{\mathcal{W}}$, where each object of the space represents a state of the system at a given time. Hence for each box of the WD-operad $\mathcal{W}$, the space $\Omega_{\mathcal{W}}$ contains the set of all possible execution paths or histories of the system component represented by that box. Additionally, to enable us to assign probabilities to subsets of these execution paths, we equip each temporal probability space with a sigma-algebra $\mathcal{F}$ of measurable events and a probability measure $\mathbb{P}$ that assigns probabilities to these events.

Morphisms in $\mathbf{TempProb}$ are adapted stochastic processes that preserve the temporal structure of the spaces, ensuring that information flows consistently through time. A morphism between two temporal probability spaces represents how the probabilistic evolution of one system component conditions or influences the probability distribution over possible evolutions of another component over time. For example, a morphism $K: \Omega_{\mathcal{W}_1} \to \Omega_{\mathcal{W}_2}$ between two temporal probability spaces can be viewed as a stochastic kernel that maps each execution path in $\Omega_{\mathcal{W}_1}$ to a probability distribution over execution paths in $\Omega_{\mathcal{W}_2}$, while respecting the temporal ordering of events. At time $t$, given history up to time $t$ in $\Omega_{\mathcal{W}_1}$, the morphism $K$ tells us the conditional probability distribution over possible states at time $t$ in $\Omega_{\mathcal{W}_2}$.

Formally, the category $\mathbf{TempProb}$ is defined as follows:

\begin{itemize}
    \item \textbf{Objects}: Temporal probability spaces $(\Omega, \mathcal{F}, \{\mathcal{F}_t\}_{t \geq 0}, \mathbb{P})$ where:
    \begin{itemize}
        \item $\Omega$ is the sample space, representing the set of all possible system trajectories or execution paths.
        \item $\mathcal{F}$ is a sigma-algebra on $\Omega$ - the collection of measurable events (subsets of trajectories) to which we can assign probabilities. Not every arbitrary subset of $\Omega$ is measurable; $\mathcal{F}$ specifies which subsets are "well-behaved" enough for probability theory.
        \item $\{\mathcal{F}_t\}_{t \geq 0}$ is a filtration - an increasing family of sigma-algebras where $\mathcal{F}_s \subseteq \mathcal{F}_t$ for $s \leq t$. This represents the accumulation of information: $\mathcal{F}_t$ captures everything we can know about the system's history up to time $t$.
        \item $\mathbb{P}: \mathcal{F} \to [0,1]$ is a probability measure assigning a likelihood to each measurable event.
    \end{itemize}

    \item \textbf{Morphisms}: Stochastic kernels $K: (\Omega_1, \mathcal{F}_1, \{\mathcal{F}_t^1\}) \to (\Omega_2, \mathcal{F}_2, \{\mathcal{F}_t^2\})$ that are adapted to the filtrations. These represent how one system component probabilistically influences another while respecting causality: at each time $t$, $K$ maps histories in $\Omega_1$ (measurable with respect to $\mathcal{F}_t^1$) to probability distributions over histories in $\Omega_2$. Formally, $K_t$ is $\mathcal{F}_t^1$-measurable for all $t$, ensuring the influence cannot depend on future information.

    \item \textbf{Composition}: For morphisms $K: \Omega_1 \to \Omega_2$ and $L: \Omega_2 \to \Omega_3$, their composition $L \circ K: \Omega_1 \to \Omega_3$ follows the Chapman-Kolmogorov equation, representing the transitive flow of probabilistic influence through chains of system components.

    \item \textbf{Monoidal Structure}: The independent product of two temporal probability spaces is defined as:
    \[(\Omega_1, \mathcal{F}_1, \{\mathcal{F}_t^1\}, \mathbb{P}_1) \otimes (\Omega_2, \mathcal{F}_2, \{\mathcal{F}_t^2\}, \mathbb{P}_2)\]
    \begin{itemize}
        \item Sample space: $\Omega_1 \times \Omega_2$ (pairs of independent trajectories)
        \item Sigma-algebra: $\mathcal{F}_1 \otimes \mathcal{F}_2$ (product sigma-algebra)
        \item Filtration: $\mathcal{F}_t^1 \otimes \mathcal{F}_t^2$ at each time $t$
        \item Measure: $\mathbb{P}_1 \times \mathbb{P}_2$ (product measure)
    \end{itemize}
\end{itemize}

This category captures the essential features of complex systems: information accumulates through time (filtration), future states depend probabilistically on past states (stochastic kernels), temporal ordering enforces causality (adaptedness), and independent subsystems can evolve in parallel (monoidal structure).

\subsubsection{Example: Neural Spike Chains}

As a concrete example of $\mathbf{TempProb}$, consider a simple system with two neurons arranged in sequence:

\[(input) \xrightarrow{} [neuron_1] \xrightarrow{} [neuron_2] \xrightarrow{} (output)\]

Each neuron fires with a stochastic spike when its input exceeds a certain threshold, with some probability. For an input voltage of $x$ volts, the sample space $\Omega$ contains all conceivable sequences, including acausal ones like backwards information flow. However, we focus on the $\sigma$-algebra $\mathcal{F}$ which contains only measurable events - causally valid sequences that respect temporal ordering.

Examples of events in $\mathcal{F}$ include:
\begin{itemize}
    \item $\omega_0$: $(input = x)$ only (initial state)
    \item $\omega_1$: $(input = x) \to [neuron_1 \text{ fires at } t_1]$
    \item $\omega_2$: $(input = x) \to [neuron_1 \text{ does not fire}]$
    \item $\omega_3$: $(input = x) \leftarrow [neuron_1 \text{ fires at } t_1]$ (absurd)
    \item $\omega_4$: $(input = x) \to [neuron_1 \text{ fires at } t_1] \to [neuron_2 \text{ does not fire}]$
    \item $\omega_5$: $(input = x) \to [neuron_1 \text{ fires at } t_2] \leftarrow [neuron_2 \text{ fires at } t_1]$ (absurd)
    \item $\omega_6$: $(input = x) \leftarrow [neuron_1 \text{ fires at } t_2] \to [neuron_2 \text{ fires at } t_1]$ (absurd)
    \item $\omega_7$: $(input = x) \to [neuron_1 \text{ fires at } t_1] \to [neuron_2 \text{ fires at } t_2] \to (output)$
    \item etc.
\end{itemize}

Note that the internal dynamics of each neuron are abstracted away; we focus on observable spike events and their temporal ordering. The $\sigma$-algebra $\mathcal{F}$ excludes acausal sequences like $(input) \leftarrow [neuron_1] \leftarrow [neuron_2]$ - while these might exist in $\Omega$, they are not measurable events in $\mathcal{F}$.

The filtration $\{\mathcal{F}_t\}_{t \geq 0}$ captures information accumulation:
\begin{itemize}
    \item $\mathcal{F}_0$: Events knowable at $t=0$ (input state only)
    \item $\mathcal{F}_{t_1}$: Events knowable up to $t_1$ (input + neuron1 state)
    \item $\mathcal{F}_{t_2}$: Events knowable up to $t_2$ (full system state, including output)
\end{itemize}

Each event has an associated probability:
\begin{align}
\mathbb{P}(\omega_1) &= P(\text{neuron}_1 \text{ fires} \mid \text{input} = x) \\
\mathbb{P}(\omega_7) &= P(\text{neuron}_1 \text{ fires} \mid x) \cdot P(\text{neuron}_2 \text{ fires} \mid \text{neuron}_1 \text{ fired})
\end{align}

\subsubsection{Example: Composition of two spaces}

Now consider two temporal probability spaces $\Omega_1$ and $\Omega_2$ representing two components in sequence, with a morphism $K: \Omega_1 \to \Omega_2$ representing how the first component influences the second over time. For simplicity we decompose the above example into two stochastic kernels: $K_1$ mapping input states to $neuron_1$ firing states, and $K_2$ mapping $neuron_1$ states to $neuron_2$ firing states.

The composition $K_2 \circ K_1$ follows the Chapman-Kolmogorov equation:
\[
(K_2 \circ K_1)(t, \omega_{input}, A) = \int_{\Omega_{neuron1}} K_1(t, \omega_{input}, d\omega') K_2(t, \omega', A)
\]

where $A$ is a measurable set of final output states, and the integral is over all possible intermediate states of $neuron_1$.

For the concrete path where input triggers both neurons in sequence:
\begin{align}
&\mathbb{P}(\text{input} \to neuron_1 \text{ fires} \to neuron_2 \text{ fires}) \\
&= \int K_1(\text{input}, \text{neuron}_1 \text{ fires at } t_1) \\
&\quad \times K_2(\text{neuron}_1 \text{ fired at } t_1, \text{neuron}_2 \text{ fires at } t_2) \, dt_1
\end{align}

This sums over all possible firing times $t_1$ for $neuron_1$, weighted by their probabilities.

More explicitly:
\[
= \mathbb{P}(\text{neuron}_1 \text{ fires} \mid \text{input}) \times \mathbb{P}(\text{neuron}_2 \text{ fires} \mid \text{neuron}_1 \text{ fired})
\]

The key property is that composition preserves adaptedness: the composite morphism $K_2 \circ K_1$ remains $\mathcal{F}_t$-measurable, ensuring causality is maintained. Information can only flow forward in time through the composition.

\subsection{$\sigma$-operads: TempProb-Enriched WD-Operads}

We now define $\sigma$-operads as WD-operads enriched in $\mathbf{TempProb}$. Let $\mathcal{W}$ be the standard operad of wiring diagrams with interfaces (finite sets of typed ports) as objects and wiring diagrams as morphisms.

A $\sigma$-operad $\mathcal{W}_{\sigma}$ is the $\mathbf{TempProb}$-enrichment of $\mathcal{W}$, where:
\begin{itemize}
    \item \textbf{Objects}: Same as $\mathcal{W}$ - interfaces representing system boundaries.
    \item \textbf{Hom-objects}: $\mathcal{W}_{\sigma}(X,Y)$ is a temporal probability space rather than a set. Each wiring diagram now carries probabilistic temporal dynamics.
    \item \textbf{Composition}: Operadic composition $\circ$ combined with stochastic composition in $\mathbf{TempProb}$, yielding the temporal evolution of composite systems.
\end{itemize}

\begin{figure}[ht]
\centering
\input{figures/sigma_operad_diagram}
\caption{$\sigma$-operads as TempProb-enriched wiring diagrams. The top shows the enrichment process: standard wiring diagrams (left) become enriched with temporal probability structures (right), where each port carries stochastic processes $X(t)$ and hom-objects are temporal probability spaces. The middle illustrates the components: temporal probability spaces with filtrations and stochastic kernels preserving causality. The bottom demonstrates operadic composition, combining topological wiring with stochastic composition via the Chapman-Kolmogorov equation.}
\label{fig:sigma_operad}
\end{figure}

\subsubsection{Temporal Causality through Ports}

In $\sigma$-operads, each port carries temporal probabilistic information:
\begin{itemize}
    \item Each port $p$ is associated with an adapted stochastic process $X_p = \{X_p(t)\}_{t \geq 0}$ representing the temporal evolution of information at that interface.
    \item Wires connecting ports encode conditional temporal dependence: if port $p$ connects to port $q$, then $X_q(t)$ depends on the history $\{X_p(s)\}_{s \leq t}$. For the markovian case, this dependence is only on $X_p(t)$.
    \item The filtration structure ensures causality: information flows from past to future, never backwards in time, so even though $\Omega$ contains all trajectories, the filteration removes (or assigns zero probability to) any trajectories that violate causal ordering.
\end{itemize}

\subsubsection{Composition of Temporal Morphisms}

When composing morphisms in $\mathcal{W}_{\sigma}$, we combine both the topological composition of wiring diagrams and the stochastic composition in $\mathbf{TempProb}$:

\begin{enumerate}
    \item \textbf{Topological Composition}: Standard wiring diagram composition connects outputs to inputs through interface matching. The resulting wiring diagram represents the overall system architecture with overall inputs and outputs.
    \item \textbf{Temporal Composition}: The stochastic processes at connected ports are composed using the Chapman-Kolmogorov equation, ensuring that temporal dependencies chain correctly through the composite system.
    \item \textbf{Filtration Compatibility}: The composed system's filtration is the natural extension that preserves the temporal ordering and causal structure. This prevents two operads from "looking into the future" of one another during composition.
\end{enumerate}

This composition naturally models how complex systems evolve: subsystems with their own temporal dynamics are connected through their interfaces, creating a larger system whose temporal evolution respects the causal flow through the network structure.
